{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cca2c1c9",
   "metadata": {},
   "source": [
    "#  <font color = darkblue size =6.5><center> Creating word2vec with dataset we have\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89801fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import gensim\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3d26e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\DELL\\Documents\\NLP\\Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd5c42fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0\n",
       "1  When I put this movie in my DVD player, and sa...      0\n",
       "2  Why do people who do not know what a particula...      0\n",
       "3  Even though I have great interest in Biblical ...      0\n",
       "4  Im a die hard Dads Army fan and nothing will e...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9652051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocssed_text = data.text.apply(gensim.utils.simple_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a3c4ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [grew, up, watching, and, loving, the, thunder...\n",
       "1        [when, put, this, movie, in, my, dvd, player, ...\n",
       "2        [why, do, people, who, do, not, know, what, pa...\n",
       "3        [even, though, have, great, interest, in, bibl...\n",
       "4        [im, die, hard, dads, army, fan, and, nothing,...\n",
       "                               ...                        \n",
       "39995    [western, union, is, something, of, forgotten,...\n",
       "39996    [this, movie, is, an, incredible, piece, of, w...\n",
       "39997    [my, wife, and, watched, this, movie, because,...\n",
       "39998    [when, first, watched, flatliners, was, amazed...\n",
       "39999    [why, would, this, film, be, so, good, but, on...\n",
       "Name: text, Length: 40000, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocssed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a645fac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords_remove(data):\n",
    "    from nltk.corpus import stopwords\n",
    "    stop = stopwords.words('english')\n",
    "    clean_text = [x for x in data if x not in stop ]\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab17c45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_text = preprocssed_text.apply(stopwords_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4879e205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [grew, watching, loving, thunderbirds, mates, ...\n",
       "1        [put, movie, dvd, player, sat, coke, chips, ex...\n",
       "2        [people, know, particular, time, past, like, f...\n",
       "3        [even, though, great, interest, biblical, movi...\n",
       "4        [im, die, hard, dads, army, fan, nothing, ever...\n",
       "                               ...                        \n",
       "39995    [western, union, something, forgotten, classic...\n",
       "39996    [movie, incredible, piece, work, explores, eve...\n",
       "39997    [wife, watched, movie, plan, visit, sicily, st...\n",
       "39998    [first, watched, flatliners, amazed, necessary...\n",
       "39999    [would, film, good, gross, estimated, award, n...\n",
       "Name: text, Length: 40000, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04868b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(window=10,min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcb305ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c44886f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80fa909e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9072683, 9751756)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(final_text,total_examples=model.corpus_count,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd3d3317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('terrible', 0.8398222923278809),\n",
       " ('horrible', 0.8370888829231262),\n",
       " ('awful', 0.82902991771698),\n",
       " ('sucks', 0.7677676677703857),\n",
       " ('worse', 0.7516876459121704),\n",
       " ('sucked', 0.7479852437973022),\n",
       " ('ok', 0.735350489616394),\n",
       " ('stupid', 0.7346734404563904),\n",
       " ('pathetic', 0.7335866689682007),\n",
       " ('lame', 0.7330421805381775)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "471b422a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52500445"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1='low',w2='high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cad619a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.doesnt_match(['car','rat','horse','tower','dog']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b8a541",
   "metadata": {},
   "source": [
    "#  <font color = darkblue size =6.5><center> Using Pretrained Word2vec Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8393cebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c060bb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r'C:\\Users\\DELL\\Documents\\NLP\\GoogleNews-vectors-negative300.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6486bdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format(filename,binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c249744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['google'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b8324b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queens', 0.739944338798523),\n",
       " ('princess', 0.7070532441139221),\n",
       " ('king', 0.6510956883430481),\n",
       " ('monarch', 0.6383602023124695),\n",
       " ('very_pampered_McElhatton', 0.6357026696205139),\n",
       " ('Queen', 0.6163407564163208),\n",
       " ('NYC_anglophiles_aflutter', 0.6060680150985718),\n",
       " ('Queen_Consort', 0.5923796892166138),\n",
       " ('princesses', 0.5908074975013733),\n",
       " ('royal', 0.5637185573577881)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('queen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60af0d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kings', 0.7138045430183411),\n",
       " ('queen', 0.6510956883430481),\n",
       " ('monarch', 0.6413194537162781),\n",
       " ('crown_prince', 0.6204220056533813),\n",
       " ('prince', 0.6159993410110474),\n",
       " ('sultan', 0.5864824056625366),\n",
       " ('ruler', 0.5797567367553711),\n",
       " ('princes', 0.5646552443504333),\n",
       " ('Prince_Paras', 0.5432944297790527),\n",
       " ('throne', 0.5422105193138123)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be9b190",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5221ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prediction:\n",
    "    estimating the output variable"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a661861c",
   "metadata": {},
   "source": [
    "Regression:\n",
    "    Predicting a countinuos value of the output feature.\n",
    "Classification:\n",
    "    predicting the category of the output variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db16a91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Output feature/Targeted variable/dependent variable(y):\n",
    "    is the one we re suppose to predict\n",
    "    \n",
    "Input features/independent variables(x1,x2,x3....xn):\n",
    "    these are the features i have for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3a4501",
   "metadata": {},
   "outputs": [],
   "source": [
    "Linear Regression:\n",
    "    LR is a machine learning algorithm that falls under suprived learning. THis is a supervised machine learning algorithm.\n",
    "    This model basically describes the relation betweeen targeted variable & the input variables by fitting a line on the observed data.\n",
    "    the targeted variable is linearly related to the input variabble\n",
    "    It is most simplest machine learning algorithms that predicts numerical output.\n",
    "    It is also called as ordinary least squared algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced1ec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "Multinomial regression:\n",
    "    when we have more the 1 input variable for a linear regression then it would be multinomial linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b53a8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Equation of a straight line:\n",
    "    y = mx + c \n",
    "    y: output variable\n",
    "    x: input variable\n",
    "    m: slope\n",
    "    c: coefficient/ intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a14507",
   "metadata": {},
   "outputs": [],
   "source": [
    "m (slope): angle of inclination\n",
    "    m = sum((x-xm)(y-ym))/sum(x-xm)^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7272bc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best fit line:\n",
    "    is that one line which is closest to the maximum data points on the graph.\n",
    "    This is also known as regression line.\n",
    "    best fit line always passes through mean point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d461248",
   "metadata": {},
   "outputs": [],
   "source": [
    "To find best fit line:\n",
    "    in the backened it uses gradient descent algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b441ec1",
   "metadata": {},
   "source": [
    "## How does best fit line is found by machine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a2c965",
   "metadata": {},
   "outputs": [],
   "source": [
    "    For the same it uses Gradient Descent Algorithm. The equation of error is an equation of sum of squared errors. such a quadratic equation when ploted against the value of m,c,& e, it aquires a owl shape in the plot. such a bowl shape would have a definte minimal point where the value of error is lowest.This is the global mima point.\n",
    "    The algorithm finds the absolute minima point which is also called as the global minima point.\n",
    "    The line that is formed using the cordinates of m & c at the global minima point is the best fit line.\n",
    "    Ut finds this point using the partial derivitives dy/dx. while using the partial derivatives it moves in the direction where the error would drop. & it is applied on m & c one at a time & so it is partial derivatives.\n",
    "    Learning Step: this is a step taken in the direction of globam minima point in such a way that the next value of m would differ from the current value of m. For the same it uses bond driver algorithm. Bond driver algorithm lowers the value of alpha (learning step).\n",
    "    Local minima points are the several others points which the alogorithm finds before arriving at global minima point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d7f458",
   "metadata": {},
   "source": [
    "## How To Evaluate a Regression Model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20c942d",
   "metadata": {},
   "outputs": [],
   "source": [
    "The most common way to evaluate a regression model is by calculating MSE, RMSE, R square & Adjusted R square.\n",
    "\n",
    "MSE:\n",
    "      MSE=(sumation(yi-yp)^2)/n\n",
    "        where n is the no. of data points\n",
    "        yi=actual data points\n",
    "        yp=predicted data points  \n",
    "        \n",
    "        \n",
    "Note: Lower the value of MSE or RMSE. Better is the model. The best fit line is a good fit to the data points.\n",
    "    \n",
    "    RMSE=sqrt((sumation(yi-yp)^2)/n)\n",
    "        where n is the no. of data points\n",
    "        yi=actual data points\n",
    "        yp=predicted data points  \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4fa89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "While the mse tells us about the avg squared error of all the predicted values from the actual values of y. we need to know how much the model is reliable. Using R squared we can know that how much the linear regression model is good for prediction.\n",
    "The range of value of R squared will vary from 0-1. closer the value to 1, it is good fit & model is more reliable & accurate. & if the value of R squared is less, it model is poorly performing.\n",
    "\n",
    "R squared is also called as coefficient od determination.\n",
    "R^2: it indicates tge proportion of total actual data points that lie on or very close to the best fit line created by the regression model."
   ]
  },
  {
   "cell_type": "raw",
   "id": "8ab9b55a",
   "metadata": {},
   "source": [
    "R^2 can be begative when the best fit line is worst than the mean line.\n",
    "In actaul scenarios, you'll never have the value of r square to be negative.\n",
    "R^2 can be negative when the chosen model does not follow the trend of the data or the model is not able to undestand the underlying pattern of the data. so fits worse than the mean line (horizontal line)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2581cfad",
   "metadata": {},
   "source": [
    "Corelation: Tells us about how well the independent & dependent features are related.\n",
    "    The value of R varies from -1 to 1.\n",
    "    For R to be good:\n",
    "        R > 0.7\n",
    "        R < -0.7\n",
    "        \n",
    "    otherwise the correlation is bad!\n",
    "    \n",
    "    r (Pearson's correlation) =  sum((xi-xm)*(yi-ym)) / sqrt(sum(((xi-xm)^2) * ((yi-ym)^2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3204d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "The Value of R^2 increases with good relationships (the independent feature that strikes good corelation with dependent feature) but it also increases with fluke relationship(the independent feature has bad corelation with dependentndent feature)\n",
    "\n",
    "Adjusted R square: It increases with good corelation & decreases with bad correlation.\n",
    "    \n",
    "    R^2 adjusted = 1 - ((1-R^2)(N-1) / N-p-1)\n",
    "    \n",
    "    where,\n",
    "    R^2 = R square\n",
    "    p= No.of features, columns, dimension, predictors\n",
    "    N= No. of observation, total sample size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe911408",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78f423c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement cv2 (from versions: none)\n",
      "ERROR: No matching distribution found for cv2\n"
     ]
    }
   ],
   "source": [
    "!pip install cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01517709",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-7f8838f0a3d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB,BernoulliNB\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37d5c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "scanned pdf:\n",
    "    1. pdf2image\n",
    "\n",
    "readable pdf:\n",
    "    1. pdftotext\n",
    "    2. tabula-py (tabular data from pdf)\n",
    "    3. camelot ((tabular data from pdf))\n",
    "    4. PyPdf2\n",
    "    \n",
    "image to text:\n",
    "    Image processing steps:\n",
    "        1. Skew correction by using openCV ()\n",
    "        2. Noise removal\n",
    "        \n",
    "    OCR:\n",
    "        1. Pytesseract(open source)\n",
    "        2. google vision\n",
    "        3. amazon textract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5b9e48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\RahulK\\\\Velocity_Sep_21\\\\01_04'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1aabea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"movie_reviews\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc7261b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative', 'positive']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders = os.listdir(folder_path)\n",
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f94ea034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'movie_reviews\\\\negative'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_review_path = folder_path + \"positive\"\n",
    "pos_review_path\n",
    "neg_review_path = folder_path + \"negative\"\n",
    "neg_review_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac10ae67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_review_txt_files = glob.glob(f\"{pos_review_path}\\\\*.txt\")\n",
    "neg_review_txt_files = glob.glob(f\"{neg_review_path}\\\\*.txt\")\n",
    "# pos_review_txt_files # list of text files \n",
    "len(neg_review_txt_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "64951988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_words(text):\n",
    "    ps = PorterStemmer()\n",
    "    text_list = []\n",
    "    tokens = word_tokenize(text)\n",
    "    for word in tokens:\n",
    "        word = ps.stem(word)\n",
    "        text_list.append(word)\n",
    "    text = ' '.join(text_list)\n",
    "    print(text)\n",
    "    return text\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "\n",
    "def get_pos_tag(word):\n",
    "    tag = pos_tag([word])[0][1][0].lower()\n",
    "    return tag\n",
    "\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    lemma = WordNetLemmatizer()\n",
    "    text_list = []\n",
    "    tokens = word_tokenize(text)\n",
    "    for word in tokens:\n",
    "        print(word)\n",
    "        word = lemma.lemmatize(word,pos = get_pos_tag(word))\n",
    "        text_list.append(word)\n",
    "    text = ' '.join(text_list)\n",
    "    print(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2e85d38b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "films\n",
      "adapted\n",
      "from\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'i'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-132-40cfb1576306>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[^A-Za-z]+'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#     text = stem_words(text)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlemmatize_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mreview_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-131-9ecb080d0775>\u001b[0m in \u001b[0;36mlemmatize_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mword\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlemma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_pos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mtext_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rahul\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\nltk\\stem\\wordnet.py\u001b[0m in \u001b[0;36mlemmatize\u001b[1;34m(self, word, pos)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNOUN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mlemmas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_morphy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlemmas\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rahul\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py\u001b[0m in \u001b[0;36m_morphy\u001b[1;34m(self, form, pos, check_exceptions)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[1;31m#    find a match or you can't go any further\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mexceptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0msubstitutions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMORPHOLOGICAL_SUBSTITUTIONS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'i'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "review_list = []\n",
    "for file_name in pos_review_txt_files:\n",
    "    f = open(file_name,'r')\n",
    "    text = f.read()\n",
    "    text = re.sub('[^A-Za-z]+', ' ',text)\n",
    "    text = stem_words(text)\n",
    "#     text = lemmatize_text(text)\n",
    "    f.close()\n",
    "    review_list.append(text)\n",
    "    \n",
    "for file_name in neg_review_txt_files:\n",
    "    f = open(file_name,'r')\n",
    "    text = f.read()\n",
    "    text = text.lower()\n",
    "    text = re.sub('[^A-Za-z]+', ' ',text)\n",
    "    f.close()\n",
    "    review_list.append(text)\n",
    "    \n",
    "len(review_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55010f54",
   "metadata": {},
   "source": [
    "# Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a571a7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_target = np.ones(len(pos_review_txt_files),dtype = int)\n",
    "neg_target = np.zeros(len(neg_review_txt_files),dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6fd81c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.full(10,2)\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b6b947c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "1995    0\n",
       "1996    0\n",
       "1997    0\n",
       "1998    0\n",
       "1999    0\n",
       "Length: 2000, dtype: int32"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.append(pos_target,neg_target)\n",
    "y = pd.Series(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8220f4a7",
   "metadata": {},
   "source": [
    "# Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8910e043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaron</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>ably</th>\n",
       "      <th>aboard</th>\n",
       "      <th>abound</th>\n",
       "      <th>abruptly</th>\n",
       "      <th>...</th>\n",
       "      <th>youth</th>\n",
       "      <th>yup</th>\n",
       "      <th>zane</th>\n",
       "      <th>zany</th>\n",
       "      <th>zellweger</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeta</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zooms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 7818 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aaron  abandon  abandoned  abilities  ability  able  ably  aboard  \\\n",
       "0         0        0          0          0        0     0     1       0   \n",
       "1         0        0          0          0        0     0     0       0   \n",
       "2         0        0          0          0        0     0     0       0   \n",
       "3         0        0          0          0        0     0     0       1   \n",
       "4         0        0          0          0        0     0     0       0   \n",
       "...     ...      ...        ...        ...      ...   ...   ...     ...   \n",
       "1995      0        0          0          0        0     0     0       0   \n",
       "1996      0        0          0          0        1     0     0       0   \n",
       "1997      0        0          0          0        1     0     0       0   \n",
       "1998      0        0          0          0        0     0     0       0   \n",
       "1999      0        0          0          0        0     0     0       0   \n",
       "\n",
       "      abound  abruptly  ...  youth  yup  zane  zany  zellweger  zero  zeta  \\\n",
       "0          0         0  ...      0    0     0     0          0     0     0   \n",
       "1          0         0  ...      0    0     0     0          0     0     0   \n",
       "2          0         0  ...      0    0     0     0          0     0     0   \n",
       "3          0         0  ...      0    0     0     0          0     0     0   \n",
       "4          0         0  ...      0    0     0     0          0     0     0   \n",
       "...      ...       ...  ...    ...  ...   ...   ...        ...   ...   ...   \n",
       "1995       0         0  ...      0    0     0     0          0     0     0   \n",
       "1996       0         0  ...      0    0     0     0          0     0     0   \n",
       "1997       0         0  ...      0    0     0     0          0     0     0   \n",
       "1998       0         0  ...      0    0     0     0          0     0     0   \n",
       "1999       0         0  ...      0    0     0     0          0     0     0   \n",
       "\n",
       "      zombie  zone  zooms  \n",
       "0          0     0      0  \n",
       "1          0     0      0  \n",
       "2          0     0      0  \n",
       "3          0     0      0  \n",
       "4          0     0      0  \n",
       "...      ...   ...    ...  \n",
       "1995       0     0      0  \n",
       "1996       0     0      0  \n",
       "1997       0     0      0  \n",
       "1998       0     0      0  \n",
       "1999       0     0      0  \n",
       "\n",
       "[2000 rows x 7818 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vector = CountVectorizer(lowercase=True, stop_words='english', min_df = 10)\n",
    "x_count = count_vector.fit_transform(review_list)\n",
    "column_names = count_vector.get_feature_names()\n",
    "x_cnt_vect = pd.DataFrame(x_count.toarray(),columns=column_names)\n",
    "x_cnt_vect\n",
    "\n",
    "# min_df = 5 >> It ignores the term that appears in less than 5 documents\n",
    "# min_df = 0.05 >> It ignores the term that appears in less than 5% documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c441f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bda59363",
   "metadata": {},
   "source": [
    "# TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "80f7f4fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaron</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>ably</th>\n",
       "      <th>aboard</th>\n",
       "      <th>abound</th>\n",
       "      <th>abruptly</th>\n",
       "      <th>...</th>\n",
       "      <th>youth</th>\n",
       "      <th>yup</th>\n",
       "      <th>zane</th>\n",
       "      <th>zany</th>\n",
       "      <th>zellweger</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeta</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zooms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078118</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.03594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 7818 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aaron  abandon  abandoned  abilities   ability  able      ably   aboard  \\\n",
       "0       0.0      0.0        0.0        0.0  0.000000   0.0  0.078118  0.00000   \n",
       "1       0.0      0.0        0.0        0.0  0.000000   0.0  0.000000  0.00000   \n",
       "2       0.0      0.0        0.0        0.0  0.000000   0.0  0.000000  0.00000   \n",
       "3       0.0      0.0        0.0        0.0  0.000000   0.0  0.000000  0.03594   \n",
       "4       0.0      0.0        0.0        0.0  0.000000   0.0  0.000000  0.00000   \n",
       "...     ...      ...        ...        ...       ...   ...       ...      ...   \n",
       "1995    0.0      0.0        0.0        0.0  0.000000   0.0  0.000000  0.00000   \n",
       "1996    0.0      0.0        0.0        0.0  0.041443   0.0  0.000000  0.00000   \n",
       "1997    0.0      0.0        0.0        0.0  0.065398   0.0  0.000000  0.00000   \n",
       "1998    0.0      0.0        0.0        0.0  0.000000   0.0  0.000000  0.00000   \n",
       "1999    0.0      0.0        0.0        0.0  0.000000   0.0  0.000000  0.00000   \n",
       "\n",
       "      abound  abruptly  ...  youth  yup  zane  zany  zellweger  zero  zeta  \\\n",
       "0        0.0       0.0  ...    0.0  0.0   0.0   0.0        0.0   0.0   0.0   \n",
       "1        0.0       0.0  ...    0.0  0.0   0.0   0.0        0.0   0.0   0.0   \n",
       "2        0.0       0.0  ...    0.0  0.0   0.0   0.0        0.0   0.0   0.0   \n",
       "3        0.0       0.0  ...    0.0  0.0   0.0   0.0        0.0   0.0   0.0   \n",
       "4        0.0       0.0  ...    0.0  0.0   0.0   0.0        0.0   0.0   0.0   \n",
       "...      ...       ...  ...    ...  ...   ...   ...        ...   ...   ...   \n",
       "1995     0.0       0.0  ...    0.0  0.0   0.0   0.0        0.0   0.0   0.0   \n",
       "1996     0.0       0.0  ...    0.0  0.0   0.0   0.0        0.0   0.0   0.0   \n",
       "1997     0.0       0.0  ...    0.0  0.0   0.0   0.0        0.0   0.0   0.0   \n",
       "1998     0.0       0.0  ...    0.0  0.0   0.0   0.0        0.0   0.0   0.0   \n",
       "1999     0.0       0.0  ...    0.0  0.0   0.0   0.0        0.0   0.0   0.0   \n",
       "\n",
       "      zombie  zone  zooms  \n",
       "0        0.0   0.0    0.0  \n",
       "1        0.0   0.0    0.0  \n",
       "2        0.0   0.0    0.0  \n",
       "3        0.0   0.0    0.0  \n",
       "4        0.0   0.0    0.0  \n",
       "...      ...   ...    ...  \n",
       "1995     0.0   0.0    0.0  \n",
       "1996     0.0   0.0    0.0  \n",
       "1997     0.0   0.0    0.0  \n",
       "1998     0.0   0.0    0.0  \n",
       "1999     0.0   0.0    0.0  \n",
       "\n",
       "[2000 rows x 7818 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vector = TfidfVectorizer(lowercase=True, stop_words='english', min_df = 10)\n",
    "x_tfidf = tfidf_vector.fit_transform(review_list)\n",
    "column_names = tfidf_vector.get_feature_names()\n",
    "x_tfidf_vect = pd.DataFrame(x_tfidf.toarray(),columns=column_names)\n",
    "x_tfidf_vect\n",
    "\n",
    "# min_df = 5 >> It ignores the term that appears in less than 5 documents\n",
    "# min_df = 0.05 >> It ignores the term that appears in less than 5% documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5358d3d9",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b0ddcd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_tfidf_vect, y, test_size=0.2, random_state=10, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd86b715",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4783e128",
   "metadata": {},
   "source": [
    "## 1. GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0622f9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for GNB model is : 0.68\n",
      "Confusion Matrix :\n",
      " [[144  56]\n",
      " [ 72 128]]\n",
      "Classification report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.72      0.69       200\n",
      "           1       0.70      0.64      0.67       200\n",
      "\n",
      "    accuracy                           0.68       400\n",
      "   macro avg       0.68      0.68      0.68       400\n",
      "weighted avg       0.68      0.68      0.68       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(x_train,y_train)\n",
    "\n",
    "y_pred = gnb_model.predict(x_test)\n",
    "\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy score for GNB model is :\",acc_score)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix :\\n',cnf_matrix)\n",
    "\n",
    "clf_report = classification_report(y_test, y_pred)\n",
    "print('Classification report :\\n',clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d101f9da",
   "metadata": {},
   "source": [
    "## 2. MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8875af43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for GNB model is : 0.7875\n",
      "Confusion Matrix :\n",
      " [[165  35]\n",
      " [ 50 150]]\n",
      "Classification report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.82      0.80       200\n",
      "           1       0.81      0.75      0.78       200\n",
      "\n",
      "    accuracy                           0.79       400\n",
      "   macro avg       0.79      0.79      0.79       400\n",
      "weighted avg       0.79      0.79      0.79       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb_model = MultinomialNB()\n",
    "mnb_model.fit(x_train,y_train)\n",
    "\n",
    "y_pred = mnb_model.predict(x_test)\n",
    "\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy score for GNB model is :\",acc_score)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix :\\n',cnf_matrix)\n",
    "\n",
    "clf_report = classification_report(y_test, y_pred)\n",
    "print('Classification report :\\n',clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e5851c",
   "metadata": {},
   "source": [
    "## 3. BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bd9373f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for GNB model is : 0.775\n",
      "Confusion Matrix :\n",
      " [[171  29]\n",
      " [ 61 139]]\n",
      "Classification report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.85      0.79       200\n",
      "           1       0.83      0.69      0.76       200\n",
      "\n",
      "    accuracy                           0.78       400\n",
      "   macro avg       0.78      0.77      0.77       400\n",
      "weighted avg       0.78      0.78      0.77       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bnb_model = BernoulliNB()\n",
    "bnb_model.fit(x_train,y_train)\n",
    "\n",
    "y_pred = bnb_model.predict(x_test)\n",
    "\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy score for GNB model is :\",acc_score)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix :\\n',cnf_matrix)\n",
    "\n",
    "clf_report = classification_report(y_test, y_pred)\n",
    "print('Classification report :\\n',clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b862aed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for GNB model is : 0.6675\n",
      "Confusion Matrix :\n",
      " [[129  71]\n",
      " [ 62 138]]\n",
      "Classification report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.65      0.66       200\n",
      "           1       0.66      0.69      0.67       200\n",
      "\n",
      "    accuracy                           0.67       400\n",
      "   macro avg       0.67      0.67      0.67       400\n",
      "weighted avg       0.67      0.67      0.67       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(x_train,y_train)\n",
    "\n",
    "y_pred = knn_model.predict(x_test)\n",
    "\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy score for GNB model is :\",acc_score)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix :\\n',cnf_matrix)\n",
    "\n",
    "clf_report = classification_report(y_test, y_pred)\n",
    "print('Classification report :\\n',clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "512130d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44ea6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit remark\n",
    "declined reason:\n",
    "    reason1: Data entry error : wrong aadhar name\n",
    "    reason2: declined due to mismatch of date of birth in aadhar and pan\n",
    "    reason3: decline due to mismatch of date of birth in aadhar and pan\n",
    "    reason4: error due Data entry person\n",
    "Lemmatiztion:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1ce31048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2afc7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a4f15b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_pos_tag(word):\n",
    "    tag = pos_tag([word])[0][1][0].lower()\n",
    "    return tag\n",
    "\n",
    "get_pos_tag('from')\n",
    "# def lemmatize_text(text):\n",
    "#     lemma = WordNetLemmatizer()\n",
    "#     text_list = []\n",
    "#     tokens = word_tokenize(text)\n",
    "#     for word in tokens:\n",
    "#         word = lemma.lemmatize(word,pos = get_pos_tag(word))\n",
    "#         text_list.append(word)\n",
    "#     text = ' '.join(text_list)\n",
    "#     print(text)\n",
    "#     return text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
